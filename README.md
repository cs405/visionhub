# visionhub - Professional Visual Intelligence Toolkit

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/pytorch-1.10%2B-orange)
![License](https://img.shields.io/badge/license-Apache%202.0-green)

**å…¨åŠŸèƒ½ç«¯åˆ°ç«¯è§†è§‰æ™ºèƒ½å·¥å…·åŒ…**

[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) â€¢ [æ–‡æ¡£](docs/USER_GUIDE.md) â€¢ [ç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§) â€¢ [å®‰è£…](#å®‰è£…)

</div>

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

**visionhub** æ˜¯ä¸€ä¸ªç”± **JKDCPPZzz** ç‹¬ç«‹å¼€å‘çš„å…¨åŠŸèƒ½ç«¯åˆ°ç«¯è§†è§‰æ™ºèƒ½å·¥å…·åŒ…ï¼Œä¸“ä¸ºå·¥ä¸šçº§åº”ç”¨å’Œå‰æ²¿ç ”ç©¶è®¾è®¡ï¼Œæä¾›é«˜æ€§èƒ½ã€æ¨¡å—åŒ–çš„è§†è§‰è§£å†³æ–¹æ¡ˆã€‚

- âœ… **å›¾åƒåˆ†ç±»**ï¼šæ”¯æŒ1000+ç±»åˆ«çš„æ ‡å‡†åˆ†ç±»ä»»åŠ¡
- âœ… **å›¾åƒæ£€ç´¢**ï¼šåŸºäºå‘é‡æ£€ç´¢çš„é«˜æ€§èƒ½ç›¸ä¼¼å›¾ç‰‡æœç´¢
- âœ… **äººè„¸è¯†åˆ«**ï¼šåŒ…å«1:1éªŒè¯ä¸1:Nè¯†åˆ«çš„å®Œæ•´æµæ°´çº¿
- âœ… **ç›®æ ‡æ£€æµ‹é›†æˆ**ï¼šæ— ç¼å¯¹æ¥YOLOç³»åˆ—å®ç°æ£€æµ‹+è¯†åˆ«è”åˆæ¨ç†
- âœ… **å·¥ä¸šçº§éƒ¨ç½²**ï¼šæ”¯æŒONNXã€TensorRTã€æ¨¡å‹é‡åŒ–åŠHTTPæœåŠ¡
- âœ… **è¿›é˜¶è®­ç»ƒ**ï¼šå†…ç½®çŸ¥è¯†è’¸é¦æ¡†æ¶ä¸ä¸°å¯Œçš„åº¦é‡å­¦ä¹ ç®—å­

---

## â­ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | æ•°é‡/æè¿° |
|------|----------|
| **Backboneæ¨¡å‹** | 85+ (ResNet, EfficientNet, ViT, Swin, MobileFaceNet, IR-Netç­‰) |
| **Losså‡½æ•°** | 50+ (åº¦é‡å­¦ä¹ ã€è’¸é¦ã€åˆ†ç±»Loss) |
| **æ•°æ®å¢å¼º** | 16ç§ (AutoAugment, Mixup, CutMix, GridMaskç­‰) |
| **éƒ¨ç½²æ”¯æŒ** | ONNX, TensorRT, TorchScript, é‡åŒ– |
| **ç¬¬ä¸‰æ–¹é›†æˆ** | YOLO (Ultralytics), Faissæ£€ç´¢ |
| **æ¶æ„ç‰¹ç‚¹** | æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•ä¸é‡æ„ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# ä»æºç å®‰è£…
git clone https://github.com/cs405/visionhub.git
cd visionhub
pip install -e .
```

### å›¾åƒåˆ†ç±»ç¤ºä¾‹

```python
from visionhub.ptcls.arch.backbone import build_backbone
from torchvision import transforms
from PIL import Image
import torch

# 1. åŠ è½½æ¨¡å‹
model = build_backbone('resnet50', num_classes=1000, pretrained=True)
model.eval()

# 2. é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 3. æ¨ç†
img = Image.open('demo.jpg')
img_tensor = transform(img).unsqueeze(0)

with torch.no_grad():
    output = model(img_tensor)
    prob = torch.softmax(output, dim=1)
    top5_prob, top5_idx = prob.topk(5)

print(f"Top-5: {list(zip(top5_idx[0].tolist(), top5_prob[0].tolist()))}")
```

### å›¾åƒæ£€ç´¢ç¤ºä¾‹

```python
from visionhub.ptcls.rec import RecPredictor

# æ„å»ºæ£€ç´¢ä¸æœç´¢
predictor = RecPredictor(model_name='resnet50', gallery_path='label_gallery/index')
results = predictor.search('demo.jpg', top_k=5)
```

### YOLO + è¯†åˆ«ç³»ç»Ÿ

```python
from visionhub.ptcls.tools.yolo_det_classification import YOLODetectionClassification

# åˆ›å»ºæ£€æµ‹+è¯†åˆ«ç³»ç»Ÿ
system = YOLODetectionClassification(
    yolo_model_path='yolov12n.pt',
    cls_model_name='resnet50',
    cls_checkpoint='classifier.pth',
    num_classes=100
)

# æ¨ç†
results = system.detect_and_classify('image.jpg', save_result=True)
```

---

## ğŸ“š å®Œæ•´æ–‡æ¡£

| æ–‡æ¡£ | æè¿° |
|------|------|
| [**å®Œæ•´ä½¿ç”¨æŒ‡å—**](docs/USER_GUIDE.md) | æ‰€æœ‰åŠŸèƒ½çš„è¯¦ç»†ä½¿ç”¨æ•™ç¨‹ |
| [æ•°æ®å¢å¼º&è®­ç»ƒ](docs/PRIORITY1_GUIDE.md) | æ•°æ®å¢å¼ºä¸è®­ç»ƒæŠ€å·§ |
| [éƒ¨ç½²æŒ‡å—](docs/DEPLOYMENT_GUIDE.md) | ONNX/TensorRTéƒ¨ç½²å®Œæ•´æ•™ç¨‹ |

---

## ğŸ’¡ ä¸»è¦åŠŸèƒ½

### 1. å›¾åƒåˆ†ç±»

```bash
# è®­ç»ƒ
python tools/train_classification.py \
  --data_root ./data \
  --model resnet50 \
  --epochs 100 \
  --batch_size 128 \
  --device cuda

# è¯„ä¼°
python tools/eval_classification.py \
  --model resnet50 \
  --checkpoint best.pth \
  --data_root ./data/test
```

### 2. å›¾åƒæ£€ç´¢

```bash
# è®­ç»ƒæ£€ç´¢æ¨¡å‹ï¼ˆæ”¯æŒYOLOæ•°æ®ï¼‰
python tools/train_rec_kd.py \
  --yolo_images dataset/train \
  --yolo_labels dataset/train \
  --data_yaml dataset/data.yaml \
  --use_pk --P 8 --K 4 \
  --w_triplet 1.0 --w_circle 0.2

# æ„å»ºæ£€ç´¢åº“
python tools/build_gallery.py -c configs/shitu/rec_faiss_demo.yaml

# è¯„ä¼°æ£€ç´¢æ•ˆæœ
python tools/eval_retrieval.py \
  -c configs/shitu/rec_faiss_demo.yaml \
  --gallery_images dataset/val \
  --query_images dataset/test
```

### 3. äººè„¸è¯†åˆ«

```bash
# è®­ç»ƒ
python tools/train_face_recognition.py \
  --train_root faces/train \
  --model ir_net_50 \
  --loss arcface

# 1:1éªŒè¯
python tools/face_recognition_inference.py \
  --task verify \
  --image1 face1.jpg \
  --image2 face2.jpg

# 1:Nè¯†åˆ«
python tools/face_recognition_inference.py \
  --task identify \
  --query query.jpg \
  --gallery_dir faces/gallery
```

### 4. æ¨¡å‹éƒ¨ç½²

```bash
# å¯¼å‡ºONNX
python tools/export_model.py \
  --model resnet50 \
  --checkpoint best.pth \
  --format onnx --simplify

# TensorRTåŠ é€Ÿ
python deploy/tensorrt_predictor.py \
  --mode build \
  --onnx model.onnx \
  --engine model.engine --fp16

# HTTPæœåŠ¡
python deploy/http_server.py \
  --model resnet50 \
  --checkpoint best.pth \
  --port 8080
```

---

## ğŸ“Š Backboneæ¨¡å‹åº“

### CNNç³»åˆ—ï¼ˆ60+ï¼‰
- **ResNetå®¶æ—**: ResNet18/34/50/101/152, ResNeXt, WideResNet, SE-ResNet
- **è½»é‡çº§**: MobileNetV2/V3, EfficientNet B0-B7, GhostNet, ShuffleNet
- **äººè„¸è¯†åˆ«**: MobileFaceNet, IR-Net-50/100/152
- **é«˜çº§CNN**: DenseNet, DLA, DPN, Inception, Xception

### Transformerç³»åˆ—ï¼ˆ25+ï¼‰
- **ViT**: ViT-Tiny/Small/Base, DeiT
- **Swin**: Swin-Tiny/Small/Base
- **å…¶ä»–**: ConvNeXt, MobileViT, CSWin, LeViT, PVT-V2

ğŸ‘‰ [æŸ¥çœ‹å®Œæ•´æ¨¡å‹åˆ—è¡¨](docs/USER_GUIDE.md#5-backboneæ¨¡å‹åº“)

---

## ğŸ“ Losså‡½æ•°åº“

### åº¦é‡å­¦ä¹ Lossï¼ˆ28ä¸ªï¼‰
- **åŸºç¡€**: ArcFace, CosFace, SphereFace, Triplet, Center
- **é«˜çº§**: Circle, SupCon, MSM, XBM, SoftTriple, Angular

### è’¸é¦Lossï¼ˆ16ä¸ªï¼‰
- **åŸºç¡€**: KLDiv, DKD, RKD
- **é«˜çº§**: AFD, ReviewKD, CRD, MGD

### åˆ†ç±»Lossï¼ˆ4ä¸ªï¼‰
- Focal, LabelSmoothing, Asymmetric

ğŸ‘‰ [æŸ¥çœ‹å®Œæ•´Lossåˆ—è¡¨](docs/USER_GUIDE.md#6-losså‡½æ•°åº“)

---

## ğŸ“¦ æ•°æ®å¢å¼º

**16ç§å¢å¼ºç­–ç•¥**ï¼š
- åŸºç¡€ï¼šFlip, Rotate, Crop, ColorJitter
- é«˜çº§ï¼šAutoAugment, RandAugment
- æ··åˆï¼šMixup, CutMix, FMix
- é®æŒ¡ï¼šRandomErasing, GridMask, HideAndSeek

---

## ğŸ¯ YOLOé›†æˆ

visionhubå®Œç¾é›†æˆYOLOï¼ˆUltralyticsï¼‰ï¼Œæ”¯æŒï¼š

### YOLOæ£€æµ‹ + åˆ†ç±»
```python
system = YOLODetectionClassification(
    yolo_model_path='yolov8n.pt',
    cls_model_name='resnet50',
    cls_checkpoint='classifier.pth'
)
results = system.detect_and_classify('image.jpg')
```

### YOLOæ£€æµ‹ + æ£€ç´¢
```bash
python run_pipeline.py all \
  -c configs/shitu/rec_faiss_demo.yaml \
  --yolo_train_images dataset/train \
  --yolo_train_labels dataset/train \
  --data_yaml dataset/data.yaml
```

**æ•°æ®æ ¼å¼ï¼ˆYOLOæ ‡å‡†ï¼‰**ï¼š
```
dataset/
  train/
    img1.jpg
    img1.txt  # class_id x_center y_center width height
  data.yaml   # names: [class1, class2, ...]
```

---

## ğŸš€ æ€§èƒ½å¯¹æ¯”

### æ¨ç†é€Ÿåº¦

| å¼•æ“ | å»¶è¿Ÿ | FPS | åŠ é€Ÿæ¯” |
|------|------|-----|--------|
| PyTorch (CPU) | 5.2ms | 192 | 1.0x |
| ONNX Runtime (CPU) | 3.8ms | 263 | 1.4x |
| ONNX Runtime (GPU) | 2.5ms | 400 | 2.1x |
| **TensorRT FP16** | **0.9ms** | **1111** | **5.8x** âœ¨ |

### æ¨¡å‹å¤§å°

| æ–¹æ³• | å¤§å° | å‹ç¼©æ¯” |
|------|------|--------|
| FP32 | 98 MB | 1.0x |
| FP16 | 49 MB | 2.0x |
| **INT8é‡åŒ–** | **25 MB** | **3.9x** âœ¨ |

---

## ğŸ“– æ•™ç¨‹å’Œç¤ºä¾‹

### åˆå­¦è€…æ•™ç¨‹
1. [5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹](docs/USER_GUIDE.md#3-å¿«é€Ÿå¼€å§‹)
2. [å›¾åƒåˆ†ç±»è®­ç»ƒ](docs/USER_GUIDE.md#81-æ ‡å‡†åˆ†ç±»è®­ç»ƒ)
3. [æ¨¡å‹è¯„ä¼°](docs/USER_GUIDE.md#41-å›¾åƒåˆ†ç±»)

### è¿›é˜¶æ•™ç¨‹
1. [å›¾åƒæ£€ç´¢å®Œæ•´æµç¨‹](docs/USER_GUIDE.md#82-æ£€ç´¢æ¨¡å‹è®­ç»ƒ)
2. [YOLO + æ£€ç´¢é›†æˆ](docs/USER_GUIDE.md#9-yoloé›†æˆ)
3. [çŸ¥è¯†è’¸é¦è®­ç»ƒ](docs/USER_GUIDE.md#44-çŸ¥è¯†è’¸é¦)

### éƒ¨ç½²æ•™ç¨‹
1. [ONNXå¯¼å‡ºå’Œæ¨ç†](docs/DEPLOYMENT_GUIDE.md#1-æ¨¡å‹å¯¼å‡º)
2. [TensorRTåŠ é€Ÿ](docs/DEPLOYMENT_GUIDE.md#build-engine-from-onnx)
3. [æ¨¡å‹é‡åŒ–](docs/DEPLOYMENT_GUIDE.md#3-æ¨¡å‹é‡åŒ–)
4. [HTTPæœåŠ¡éƒ¨ç½²](docs/DEPLOYMENT_GUIDE.md#4-httpæœåŠ¡éƒ¨ç½²)

---

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
visionhub/
â”œâ”€â”€ ptcls/                    # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ arch/                 # æ¨¡å‹æ¶æ„
â”‚   â”‚   â”œâ”€â”€ backbone/         # Backboneæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ head/             # åˆ†ç±»å¤´
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ loss/                 # Losså‡½æ•°
â”‚   â”‚   â”œâ”€â”€ metric/           # åº¦é‡å­¦ä¹ Loss
â”‚   â”‚   â”œâ”€â”€ distillation/     # è’¸é¦Loss
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                 # æ•°æ®åŠ è½½
â”‚   â”‚   â”œâ”€â”€ datasets/         # æ•°æ®é›†
â”‚   â”‚   â”œâ”€â”€ augmentation/     # æ•°æ®å¢å¼º
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ metric/               # è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ rec/                  # æ£€ç´¢æ¨¡å—
â”‚   â”œâ”€â”€ face/                 # äººè„¸è¯†åˆ«
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”œâ”€â”€ tools/                    # è®­ç»ƒ/è¯„ä¼°å·¥å…·
â”‚   â”œâ”€â”€ train_classification.py
â”‚   â”œâ”€â”€ train_rec_kd.py
â”‚   â”œâ”€â”€ train_face_recognition.py
â”‚   â”œâ”€â”€ export_model.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ deploy/                   # éƒ¨ç½²å·¥å…·
â”‚   â”œâ”€â”€ onnx_predictor.py
â”‚   â”œâ”€â”€ tensorrt_predictor.py
â”‚   â”œâ”€â”€ http_server.py
â”‚   â””â”€â”€ batch_inference.py
â”œâ”€â”€ configs/                  # é…ç½®æ–‡ä»¶
â”œâ”€â”€ docs/                     # æ–‡æ¡£
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶
â”œâ”€â”€ setup.py                  # å®‰è£…è„šæœ¬
â””â”€â”€ pyproject.toml            # é¡¹ç›®é…ç½®
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md)

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [Apache 2.0](LICENSE) è®¸å¯è¯

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®å’Œæ¡†æ¶çš„æ”¯æŒï¼š

- **PyTorch**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **Ultralytics**: YOLOå®ç°
- **Faiss**: é«˜æ€§èƒ½å‘é‡æ£€ç´¢åº“
- **ONNX Runtime**: è·¨å¹³å°æ¨ç†å¼•æ“
- **TensorRT**: NVIDIAæ¨ç†åŠ é€Ÿå¼•æ“

---

## ğŸ“ è”ç³»æˆ‘ä»¬

- **Issue**: [GitHub Issues](https://github.com/cs405/visionhub/issues)
- **æ–‡æ¡£**: [å®Œæ•´æ–‡æ¡£](docs/)
- **ç¤ºä¾‹**: [examples/](examples/)

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªStarï¼â­**

Made with â¤ï¸ by JKDCPPZzz

</div>

